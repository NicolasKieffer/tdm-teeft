<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: indexator.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: indexator.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * @prettier
 */
'use strict';

/* Module Require */
const Lemmatizer = require('javascript-lemmatizer'),
  snowballFactory = require('snowball-stemmers'),
  Tagger = require('./tagger.js'),
  Filter = require('./filter.js'),
  lexicon = require('./lexicon.js'),
  TermExtraction = require('./termextractor.js');

/**
 * @constructs Indexator
 * @example &lt;caption>Example usage of 'contructor' (with paramters)&lt;/caption>
 * let options = {
 *     'filter': customFilter // According customFilter contain your custom settings
 *   },
 *   indexator = new Indexator(options);
 * // returns an instance of Indexator with custom Filter
 * @example &lt;caption>Example usage of 'contructor' (with default values)&lt;/caption>
 * let indexator = new Indexator();
 * // returns an instance of Indexator with default options
 * @param {Object} [options] - Options of constructor
 * @param {Object} [options.filter] - Options given to extractor of this instance of Indexator
 * @param {Object} [options.lexicon] - Lexicon used by tagger of this instance of Indexator
 * @param {Object} [options.stopwords] - Stopwords used by this instance of Indexator
 * @param {Object} [options.dictionary] - Dictionnary used by this instance of Indexator
 * @returns {Indexator} - An instance of Indexator
 */
const Indexator = function(options = {}) {
  const filterOpts =
    options &amp;&amp; options.filter
      ? {
          'filter': new Filter(options.filter)
        }
      : {};
  // Tagger + filter + extractor + lemmatizer
  this.tagger = new Tagger(options &amp;&amp; options.lexicon ? options.lexicon : lexicon);
  this.extractor = new TermExtraction(filterOpts);
  this.lemmatizer = new Lemmatizer();
  this.stemmer = snowballFactory.newStemmer('english');
  this.stopwords = options &amp;&amp; options.stopwords ? options.stopwords : {};
  this.dictionary = options &amp;&amp; options.dictionary ? options.dictionary : {};
  this.NOT_ALPHANUMERIC = new RegExp('\\W', 'g'); // RegExp of alphanumerique char
  this.DIGIT = new RegExp('\\d', 'g'); // RegExp of number
  this.NOUN_TAG = new RegExp(/(\|)?N[A-Z]{1,3}(\|)?/g); // RegExp of noun tag
  this.VERB_TAG = new RegExp(/(\|)?V[A-Z]{1,3}(\|)?/g); // RegExp of verb tag
  this.MAX_NOT_ALPHANUMERIC = 2; // limit of alphanumeric char
  this.MAX_DIGIT = 2; // Limit of digit
  this.MIN_LENGTH = 4; // Minimum length of token
  this.SPECIFIC_TERM = new RegExp(/^([^a-zA-Z0-9]*|[!\-;:,.?]*)(\w+)([^a-zA-Z0-9]*|[!\-;:,.?]*)$/g); // RegExp of a term between punctuation
  this.SEPARATOR = '#'; // Char separator
  return this;
};

/**
 * Extract token from a text
 * @example &lt;caption>Example usage of 'tokenize' function&lt;/caption>
 * let indexator = new Indexator();
 * indexator.tokenize('my sample sentence'); // return ['my', 'sample', 'sentence']
 * @param {String} text - Fulltext
 * @return {Array} Array of tokens
 */
Indexator.prototype.tokenize = function(text = '') {
  const words = text.split(/\s/g);
  let result = [];
  for (let i = 0; i &lt; words.length; i++) {
    const term = words[i].toLowerCase();
    // Now, a word can be preceded or succeeded by symbols, so let"s
    // split those out
    let match;
    while ((match = this.SPECIFIC_TERM.exec(term))) {
      for (let j = 1; j &lt; match.length; j++) {
        if (match[j].length > 0) {
          if (j === 2) {
            result.push(match[j]);
          } else {
            result.push(this.SEPARATOR);
          }
        }
      }
    }
  }
  return result;
};

/**
 * Translate the tag of Tagger to Lemmatizer
 * @example &lt;caption>Example usage of 'translateTag' function&lt;/caption>
 * let indexator = new Indexator();
 * indexator.translateTag(RB); // return 'adv';
 * indexator.translateTag(JJ); // return 'adj';
 * indexator.translateTag(NN); // return 'noun';
 * indexator.translateTag(NNP); // return 'noun';
 * indexator.translateTag(VBG); // return 'verb';
 * indexator.translateTag(VBN); // return 'verb';
 * @param {String} tag - Tag given by Tagger
 * @return {String} Tag who match with a Lemmatizer tag (or false)
 */
Indexator.prototype.translateTag = function(tag = '') {
  let result = false;
  if (tag === 'RB') {
    result = 'adv';
  } else if (tag === 'JJ') {
    result = 'adj';
  } else if (tag.match(this.NOUN_TAG)) {
    result = 'noun';
  } else if (tag.match(this.VERB_TAG)) {
    result = 'verb';
  }
  return result;
};

/**
 * Sanitize list of terms (with some filter)
 * @example &lt;caption>Example usage of 'sanitize' function&lt;/caption>
 * let indexator = new Indexator();
 * indexator.sanitize([ { term: 'this', tag: 'DT', lemma: 'this', stem: 'this' },
 *   { term: 'is', tag: 'VBZ' },
 *   { term: 'a', tag: 'DT' },
 *   { term: 'sample', tag: 'NN', lemma: 'sample', stem: 'sampl' },
 *   { term: 'test', tag: 'NN', lemma: 'test', stem: 'test' } ]);
 * // return [ { term: 'this', tag: 'DT', lemma: 'this', stem: 'this' },
 * //   { term: '#', tag: '#' },
 * //   { term: '#', tag: '#' },
 * //   { term: 'sample', tag: 'NN', lemma: 'sample', stem: 'sampl' },
 * //   { term: 'test', tag: 'NN', lemma: 'test', stem: 'test' } ]
 * @param {Array} terms - List of terms
 * @return {Array} Liste of sanitized terms
 */
Indexator.prototype.sanitize = function(terms = []) {
  let result = [];
  const invalid = this.tagger.tag(this.SEPARATOR)[0];
  for (let i = 0; i &lt; terms.length; i++) {
    let value = invalid;
    if (terms[i].term.length >= this.MIN_LENGTH) {
      const na = terms[i].term.match(this.NOT_ALPHANUMERIC),
        d = terms[i].term.match(this.DIGIT);
      if (
        (!na || na.length &lt;= this.MAX_NOT_ALPHANUMERIC) &amp;&amp;
        (!d || d.length &lt; this.MAX_DIGIT) &amp;&amp;
        !this.stopwords[terms[i].lemma]
      ) {
        value = terms[i];
      }
    }
    result.push(value);
  }
  return result;
};

/**
 * Lemmatize a list of tagged terms (add a property lemma &amp; stem)
 * @example &lt;caption>Example usage of 'translateTag' function&lt;/caption>
 * let indexator = new Indexator();
 * indexator.lemmatize([ { term: 'this', tag: 'DT', lemma: 'this', stem: 'this' },
 *   { term: 'is', tag: 'VBZ' },
 *   { term: 'a', tag: 'DT' },
 *   { term: 'sample', tag: 'NN', lemma: 'sample', stem: 'sampl' },
 *   { term: 'test', tag: 'NN', lemma: 'test', stem: 'test' } ]);
 * // return [ { term: 'this', tag: 'DT', lemma: 'this', stem: 'this' },
 * //   { term: '#', tag: '#' },
 * //   { term: '#', tag: '#' },
 * //   { term: 'sample', tag: 'NN', lemma: 'sample', stem: 'sampl' },
 * //   { term: 'test', tag: 'NN', lemma: 'test', stem: 'test' } ]
 * @param {Array} terms - List of tagged terms
 * @return {Array} List of tagged terms with a lemma
 */
Indexator.prototype.lemmatize = function(terms = []) {
  let result = [];
  for (let i = 0; i &lt; terms.length; i++) {
    const trslTag = this.translateTag(terms[i].tag);
    let lemma = terms[i].term;
    // If translation is possible
    if (trslTag) {
      const _lemma = this.lemmatizer.lemmas(terms[i].term, trslTag);
      if (_lemma.length > 0) {
        lemma = _lemma[_lemma.length - 1][0]; // Get the first lemma
      }
    }
    result.push({
      term: terms[i].term,
      tag: terms[i].tag,
      lemma: lemma,
      stem: this.stemmer.stem(terms[i].term)
    });
  }
  return result;
};

/**
 * Compare the specificity of two objects between them
 * @example &lt;caption>Example usage of 'compare' function&lt;/caption>
 * Indexator.compare({ 'term': 'a', 'specificity': 1 }, { 'term': 'b', 'specificity': 2 }); // return 1
 * Indexator.compare({ 'term': 'a', 'specificity': 1 }, { 'term': 'b', 'specificity': 1 }); // return 0
 * Indexator.compare({ 'term': 'a', 'specificity': 2 }, { 'term': 'b', 'specificity': 1 }); // return -1
 * @param {Object} a - First object
 * @param {Object} b - Second object
 * @return {Number} -1, 1, or 0
 */
Indexator.compare = function(a, b) {
  if (a.specificity > b.specificity) return -1;
  else if (a.specificity &lt; b.specificity) return 1;
  else return 0;
};

/**
 * Index a fulltext
 * @example &lt;caption>Example usage of 'translateTag' function&lt;/caption>
 * let indexator = new Indexator();
 * indexator.index('This is a sample sentence'); // return an object representation of indexation
 * @param {String} data - Fulltext who need to be indexed
 * @return {Object} Return a representation of fulltext (indexation &amp; more informations/statistics about tokens/terms)
 */
Indexator.prototype.index = function(data, options) {
  // Default value
  const text = {
      'keywords': [], // Keywords
      'extraction': {
        // Extraction (terms)
        'terms': {},
        'keys': []
      },
      'terms': {
        // All terms
        'tagged': [], // tagged
        'sanitized': [], // sanitized
        'lemmatized': [] // lemmatized
      },
      'tokens': [], // Token from fulltext
      'statistics': {
        // Somme statistics about
        // frequencies
        'frequencies': {
          'max': 0,
          'total': 0
        },
        // specificities
        'specificities': {
          'avg': 0,
          'max': 0
        }
      }
    },
    sort = options &amp;&amp; options.sort,
    truncate = options &amp;&amp; options.truncate;
  // Get tokens
  text.tokens = this.tokenize(data);
  // If there is no token, end of process
  if (text.tokens.length === 0) return text;
  // Tag des tokens
  text.terms.tagged = this.tagger.tag(text.tokens);
  // If there is no tagged term, end of process
  if (text.terms.tagged.length === 0) return text;
  // Lemmatize tagged terms
  text.terms.lemmatized = this.lemmatize(text.terms.tagged);
  // If there is no lemmatized term, end of process
  if (text.terms.lemmatized.length === 0) return text;
  // Sanitize all lemmatized terms
  text.terms.sanitized = this.sanitize(text.terms.lemmatized);
  // If there is no sanitized term, end of process
  if (text.terms.sanitized.length === 0) return text;
  // Extract terms
  text.extraction.terms = this.extractor.extract(text.terms.sanitized);
  text.extraction.keys = Object.keys(text.extraction.terms); // List of keys
  // If there is no extracted term, end of process
  if (text.extraction.keys.length === 0) return text;
  // Calculate some statistics of frÃ©quencies
  for (let i = 0; i &lt; text.extraction.keys.length; i++) {
    // Key in text.extraction.terms
    const key = text.extraction.keys[i];
    // Max frequency
    if (text.statistics.frequencies.max &lt; text.extraction.terms[key].frequency) {
      text.statistics.frequencies.max = text.extraction.terms[key].frequency;
    }
    // Total frequency
    text.statistics.frequencies.total += text.extraction.terms[key].frequency;
  }
  // Default value
  let dValue = Math.pow(10, -5);
  // Calculate of scores for each term &amp; Calculate the total of frequencies
  for (let i = 0; i &lt; text.extraction.keys.length; i++) {
    // Key in text.extraction.terms
    const key = text.extraction.keys[i];
    // Value of term weighting in function of its representativity in the vocabulary (dictionnary.json)
    const weighting = this.dictionary[key] || dValue;
    // Specificity = (frequency / totalFrequency) / (weighting)
    text.extraction.terms[key].specificity =
      text.extraction.terms[key].frequency / text.statistics.frequencies.total / weighting;
    // Probability = (frequency / totalFrequency)
    text.extraction.terms[key].probability = text.extraction.terms[key].frequency / text.statistics.frequencies.total;
    // Calculate the max specificity
    if (text.statistics.specificities.max &lt; text.extraction.terms[key].specificity) {
      text.statistics.specificities.max = text.extraction.terms[key].specificity;
    }
  }
  // Normalize the specificity of each term &amp; Sum of all normalized specificities
  for (let i = 0; i &lt; text.extraction.keys.length; i++) {
    // Key in text.extraction.terms
    const key = text.extraction.keys[i];
    text.extraction.terms[key].specificity /= text.statistics.specificities.max;
    text.statistics.specificities.avg += text.extraction.terms[key].specificity;
  }
  // Calcul of average specificity
  text.statistics.specificities.avg /= text.extraction.keys.length;
  // Liste of indexed terms (keywords)
  text.keywords = [];
  // Select final results
  for (let i = 0; i &lt; text.extraction.keys.length; i++) {
    // Key in text.extraction.terms
    const key = text.extraction.keys[i];
    if (!truncate || text.extraction.terms[key].specificity >= text.statistics.specificities.avg) {
      text.extraction.terms[key].term = key;
      text.keywords.push(text.extraction.terms[key]);
    }
  }
  // If result need to be sorted
  if (sort) {
    text.keywords = text.keywords.sort(Indexator.compare);
  }
  return text;
};

module.exports = Indexator;
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="Filter.html">Filter</a></li><li><a href="Indexator.html">Indexator</a></li><li><a href="Tagger.html">Tagger</a></li><li><a href="TermExtractor.html">TermExtractor</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 3.6.3</a> on Fri Oct 25 2019 21:24:22 GMT+0200 (CEST)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
